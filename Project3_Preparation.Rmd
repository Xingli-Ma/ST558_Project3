---
title: "Project3"
output: html_document
---

```{r setup, include=FALSE}
require(rmarkdown)
require(knitr)
library(caret)
library(ggplot2)
require(corrplot)
library(tidyverse)
library(DT)
knitr::opts_chunk$set(echo = TRUE)
```

## About   

### The purpose of the app    

This shiny app is created to demonstrate the American black bear data information, allow users to explore the data and make customized summaries, build and compare three models on the training set of the data, and select the best model to make predictions on the testing set.    

### The data and data source    

The American black bear distribution data come from the [iNaturalist database](https://www.inaturalist.org/). 

```{r graphics, out.width = "300px"}
knitr::include_graphics("Project3_ShinyApp/iNaturalist.jpg")
```    

The data set was provided by Brent Pease of the Department of Forestry and Environmental Resources at NC State University. The data set consists of a randomly-selected set of 927 (50 km2) regions from Western North America. It has 10 variables:    
    Y: Number of black bear reports,     
    N: Number of surveys submitted, 
    forest: Proportion of the region that is forest,     
    grassland: Proportion of the region that is grassland,     
    cropland: Proportion of the region that is cropland ,     
    temp (Annual average temperature,    
    precip: Annual average precipitation,    
    humanPop: Human population,    
    protected: Indicator of whether the region includes protected lands,    
    ecoregion: Either "MARINE WEST COAST FOREST", "MEDITERRANEAN CALIFORNIA", "NORTH AMERICAN DESERTS" or "NORTHWESTERN FORESTED MOUNTAINS".       

### The functionalities of the app    

This shiny app has four tabs: **About**, **Data**, **Data Exploration**, and **Modeling**. The **About** page has a brief introduction about this app and its functionalities, as well as data description and data source. The **Data** page allows users to view and subset the data and download and save the data. The **Data Exploration** page generates different types of plots that can be specified by users and create summaries. The **Modeling** page fits three statistical models, including modeling approaches. The **Modeling** page has three tabs: **Modeling Info**, **Model Fitting**, and **Prediction**. More information relevant to each tab are available at the beginning of each page.    

## Data    

```{r read data}
# Read data and clean up data  
ABB <- read.csv("ABBdata.csv")
# Convert categorical variables to factors
ABB$protected <- as.factor(ABB$protected)
ABB$ecoregion <- as.factor(ABB$ecoregion)
ABB <- ABB[,-1]
print(str(ABB))
```    

```{r display data}
# Display data  
DT::datatable(ABB)
```


## Data Exploration    

```{r}
# Numerical summaries on the data
kable(summary(select(ABB, c(Y,N,forest, grassland,cropland,temp,precip,humanPop,protected,ecoregion
))))
```    

```{r}
# Contingency table comparing number of black bear reports by ecoregion
kable(ABB %>% group_by(ecoregion) %>% summarise(sum_Y = sum(Y)), caption = 'Number of black bear by ecoregion')
```    

    
    }
    output$dt_ecoregion <- renderText({
        knitr::kable(ABB %>% group_by(ecoregion) %>% summarise(sum_Y = sum(Y)))
    })
    
    output$dt_protected <- function(){
        ABBdata %>% group_by(protected) %>% summarise(sum_Y = sum(Y)) %>%
            knitr::kable("html") %>%
            kable_styling("striped", full_width = F)
    }
    
                                                        htmlOutput("dt_ecoregion"),
                                                        tableOutput("dt_ecoregion"),
                                                        DTOutput(outputId = "dt_ecoregion"),
                                                        br(),
                                                        br(),
                                                        htmlOutput("dt_protected"),
                                                        tableOutput("dt_protected")
                                                        
                                                        

```{r}
# Contingency table comparing number of black bear reports by whether or not protected lands
kable(ABB %>% group_by(protected) %>% summarise(sum_Y = sum(Y)), caption = 'Number of black bear by whether or not protected lands')
```



```{r}
ggplot(data = ABB) +
  geom_bar(mapping = aes(x = ecoregion, y))
```



```{r}
ABB_new <- ABB
ABB_new$P <- ABB$Y/ABB$N
ABB_new <- select(ABB_new, -c(Y, N))
ABB_new
```   
```{r}
    set.seed(558)
    ABBIndex <- createDataPartition(ABB_new$P, p = 0.7, list = FALSE)
    ABBTrain <- ABB_new[ABBIndex, ]
    ABBTest <- ABB_new[-ABBIndex, ]
    ABBTrainTest <- list(ABBTrain,ABBTest)
    head(ABBTrainTest[[1]])
```


## Model 1: Logistic Regression

```{r}
# Define training control
trctrl <- trainControl(method = "cv", number = 10)
fit1 <- train(P~ ., data = ABBTrain,
               method = "glm",
               family = "binomial",
               preProcess = c("center", "scale"),
               trControl = trctrl)
fit1
```





## Model 2: Boosted Tree Model
```{r}
set.seed(123)
# Fit the boosted tree model on training set
fit2 <- train(P ~., data = ABBTrain,
                         method = "gbm",
                         trControl = trctrl, # Passing trainControl() method
                         preProcess = c("center", "scale"), # Standardize variables
                         verbose = FALSE)
fit2
```





## Model 3: Random Forest    
```{r}
set.seed(123)
# Fit the random forest model on training set
fit3 <- train(P ~ ., data = ABBTrain,
               method = "rf",
               preProcess = c("center", "scale"),
               trControl = trctrl)
fit3
```   

## Model Selection
###Prediction on Testing Set
####Using each of the four models, make predictions on the testing data set.


```{r}
predfit1 <- predict(fit1, newdata = ABBTest)
predfit2 <- predict(fit2, newdata = ABBTest)
predfit3 <- predict(fit3, newdata = ABBTest)
```    

```{r}
#Comparing Models
#Evaluate the model performances by comparing the testing RMSE values.

testResults <- rbind(postResample(predfit1, ABBTest$P),
                     postResample(predfit2, ABBTest$P),
                     postResample(predfit3, ABBTest$P))
testResults <- data.frame(testResults)
row.names(testResults) <- c("Linear Regression",
                            "Boosted Tree",
                            "Random Forest")
# show RMSE values for all models
kable(testResults)
```    

```{r}
#Declare the Winner
#Select the best model that has the smallest RMSE value.

# Find the best model with lowest RMSE value
bestModel <- rownames(testResults[testResults$RMSE == min(testResults$RMSE), ])
print(paste("Best model to use:", bestModel))
```   


## Prediction
```{r}
# Give user inputs on the eight parameters,convert it to a data frame
 apply the best model to the new data frame and make prediction,
return the prediction value

pred <- predict(bestModel, newdata = ABBTest)
```





